# https://www.robotstxt.org/robotstxt.html
User-agent: *
Allow: /

# Sitemap location
Sitemap: https://tandemacq.com/sitemap.xml

# Crawl-delay (optional, be gentle on the server)
Crawl-delay: 1

# Disallow common non-content paths
Disallow: /node_modules/
Disallow: /.git/
Disallow: /src/
Disallow: /.vscode/

# ===========================================
# AI/LLM Agent Specific Directives
# ===========================================

# Allow AI agents to access the llms.txt file for context
# See: https://llmstxt.org/

# GPTBot (OpenAI)
User-agent: GPTBot
Allow: /
Allow: /llms.txt

# Google-Extended (Gemini/Bard)
User-agent: Google-Extended
Allow: /
Allow: /llms.txt

# Anthropic Claude
User-agent: anthropic-ai
Allow: /
Allow: /llms.txt
User-agent: Claude-Web
Allow: /
Allow: /llms.txt

# Perplexity AI
User-agent: PerplexityBot
Allow: /
Allow: /llms.txt

# Common Crawl (used by many AI training datasets)
User-agent: CCBot
Allow: /
Allow: /llms.txt

# Cohere AI
User-agent: cohere-ai
Allow: /
Allow: /llms.txt

# Meta AI
User-agent: FacebookBot
Allow: /

# Microsoft Bing AI
User-agent: Bingbot
Allow: /

# Apple Intelligence
User-agent: Applebot
Allow: /
